# Kunitz Domain HMM Pipeline

## Indice

- [Introduction](#introduction)
- [Recommended Packages](#recommended-packages)
- [Required Files](#required-files)
- [Workflow](#workflow)
- [File Description](#file-description)

---

## Introduction

This repository presents the implementation of a computational workflow designed to construct and evaluate a Profile Hidden Markov Model (HMM) focused on a specific protein domain of interest. The project involves generating a structure-based multiple sequence alignment of representative domain-containing proteins, from which an HMM is built and calibrated. The resulting model is tested against both positive (domain-containing) and negative (domain-absent) protein sequences to assess its classification performance. Additionally, a sequence-based HMM—built using an alignment generated by MUSCLE—is developed for comparative evaluation. This analysis aims to highlight the impact of structural information on the sensitivity and specificity of domain detection. The project was carried out as part of a Laboratory in Bioinformatics course during my MSc in Bioinformatics, and integrates principles of structural bioinformatics, statistical modeling, and sequence analysis.

---

## Recommended Packages

The pipeline depends on the following bioinformatics tools and libraries, which must be installed before running the workflow. Most of them are available through the conda package manager (via the Bioconda or Conda-Forge channels):

- **CD-HIT**: Groups highly similar protein sequences into clusters to reduce redundancy in input datasets. This ensures that the training set for the HMM is non-redundant.  
  `bash conda install -c bioconda cd-hit`

- **HMMER**: Core tool for building Profile Hidden Markov Models and scanning sequence databases for domain detection. Essential for training and testing the structural HMM.  
  `bash conda install -c bioconda hmmer`

- **BLAST+**: Performs similarity searches (via blastp) to retrieve known homologous sequences or verify hits. Useful for validating HMM predictions.  
  `conda install -c bioconda blast`

- **MUSCLE** (Optional — only needed for sequence-based HMM comparison): Generates multiple sequence alignments from sequence data, used to build the baseline sequence-based HMM for comparison against the structure-based model.  
  `conda install -c bioconda muscle`

- **Biopython**: Required to run `get_seq.py`, a script that extracts specific sequences from FASTA files based on identifiers. Enables automation and parsing of biological data formats.  
  `conda install -c conda-forge biopython`

---

## Required Files

- [`rcsb_pdb_custom_report_20250407015737.csv`](./rcsb_pdb_custom_report_20250407015737.csv) – Custom report downloaded from RCSB PDB, filtered for Kunitz domain structures.
- [`script_recover_representative_kunitz.sh`](./script_recover_representative_kunitz.sh) – Script to extract representative PDB IDs of Kunitz domain structures.
- [`create_hmm_str.sh`](./create_hmm_str.sh) – Script to build the structural HMM model from the structural alignment.
- [`create_testing_sets.sh`](./create_testing_sets.sh) – Script to generate the test sets and compute performance metrics.
- [`performance.py`](./performance.py) – Python script to compute evaluation metrics (MCC, precision, TPR, etc.) for model predictions.
- [`getseq.py`](./getseq.py) – Python script to extract specific sequences from a FASTA file based on a list of accession IDs.
- It is also essential to download all protein sequences available in the Swiss-Prot database, as they will be used to construct the negative dataset.


---

## Workflow

1. **Download Swiss-Prot FASTA**  
### Step 2: Extract Representative Kunitz Domain Structures
Run the following script to collect a set of representative PDB entries annotated with the Kunitz domain:

bash script_recover_representative_kunitz.sh
This generates a file named tmp_pdb_efold_ids.txt containing the PDB codes.

Note: Before uploading the list to PDBeFold, manually check and filter out any sequences that are too long, too short, or contain disordered tails. This improves alignment consistency and HMM quality.

Step 3: Perform Structure-Based Multiple Sequence Alignment
Go to the PDBeFold Multi Alignment Tool

Set the following parameters:

Mode: Multiple

Source: List of PDB codes

Upload the file tmp_pdb_efold_ids.txt

Download the FASTA alignment

Paste the downloaded content into the file:

Copia
Modifica
pdb_kunitz_rp.ali
### Step 4: Build and Evaluate the Structural HMM Model

Run the following scripts to build the structural HMM and evaluate its performance:

```bash
bash create_hmm_str.sh
bash create_testing_sets.sh
This step will:

Build a structural HMM using the multiple alignment from PDBeFold (pdb_kunitz_rp.ali)

Filter out training sequences from the Swiss-Prot dataset (uniprot_sprot.fasta)

Generate positive (pos_1.fasta, pos_2.fasta) and negative (neg_1.fasta, neg_2.fasta) test sets

Automatically compute optimal E-value thresholds using 2-fold cross-validation (based on Matthews Correlation Coefficient, MCC)

Evaluate model performance across:

Set 1 using Set 2’s threshold

Set 2 using Set 1’s threshold

Combined set using both thresholds

Output evaluation metrics (MCC, precision, recall, FPR, FNR) to:

Copia
Modifica
hmm_results_strali.txt
False positives and false negatives will also be listed in the output files.







---

## File Description

- `create_hmm_str.sh` – builds structure-based HMM  
- `create_testing_sets.sh` – generates test sets & evaluates  
- `create_hmm_seq.sh` – builds sequence-based HMM (MUSCLE)  
- `get_seq.py` – extracts sequences from FASTA  
- `performance.py` – calculates MCC, precision, etc.  
- `*.class` – classification result files  
- `*.hmm`, `*.fasta` – alignment and HMM data
